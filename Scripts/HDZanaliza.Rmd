---
title: "HDZ na društvenim mrežama"
author: "Lux"
date: '03 05 2021'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

```{r paketi, echo=FALSE, message=FALSE, warning=FALSE}

library(tidyverse)
library(janitor)
library(tidyverse)
library(httr)
library(jsonlite)
library(lubridate)
library(tidytext)
library(data.table)
library(wordcloud)
library(knitr)
library(gridExtra)
library(grid)
library(topicmodels)
library(rvest)
library(igraph)
library(ggraph)
library(scales)
library(widyr)
library(kableExtra)
```

```{r podatci, echo=FALSE, message=FALSE, warning=FALSE}
hdz2 <- read.csv2("../Data/HDZscv.csv") %>%
  select(X.3) %>%
  row_to_names(.,1) %>%
  mutate(Published = substr(Published,1,10)) #%>%
#mutate(Datum = as.Date(Published,"d%.m%.Y%"))

Datum  <- mutate(hdz2, b2= as.Date(Published, format= "%d.%m.%Y")) %>%
  select(-Published) %>%
  rename(Datum =b2)


hdz <- readxl::read_excel("../Data/HDZ.xlsx") %>% 
  row_to_names(.,1) %>% 
  clean_names() %>%
  select(-c(1,17:25,28:33,37:41)) %>%
  select(-published,-indexed,-category,-image,-languages) %>%
  cbind.data.frame(Datum)
```

```{r leksikoni, echo=FALSE, message=FALSE, warning=FALSE}
source("../Mfiles/mfiles.R")

CroSentilex_n <- read.delim(mfiles_downlaod_txt("0", 136679, 136711, ext = ".txt"),
                            header = FALSE,
                            sep = " ",
                            stringsAsFactors = FALSE) %>% 
  rename(word = "V1", sentiment = "V2" ) %>%
  mutate(brija = "NEG")

CroSentilex_p <- read.delim(mfiles_downlaod_txt("0", 136681, 136713, ext = ".txt"),
                            header = FALSE,
                            sep = " ",
                            stringsAsFactors = FALSE) %>% 
  rename(word = "V1", sentiment = "V2" ) %>%
  mutate(brija = "POZ")
Crosentilex_sve <- rbind(setDT(CroSentilex_n), setDT(CroSentilex_p))
#head(Crosentilex_sve)

CroSentilex_Gold  <- read.delim2(mfiles_downlaod_txt("0", 136680, 136712, ext = ".txt"),
                                 header = FALSE,
                                 sep = " ",
                                 stringsAsFactors = FALSE) %>%
  rename(word = "V1", sentiment = "V2" ) 

CroSentilex_Gold[1,1] <- "dati"
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "-", "1")
CroSentilex_Gold$sentiment <- str_replace(CroSentilex_Gold$sentiment , "\\+", "2")
CroSentilex_Gold$sentiment <- as.numeric(unlist(CroSentilex_Gold$sentiment))
#head(CroSentilex_Gold)

# leksikoni
stopwords_cro <- get_stopwords(language = "hr", source = "stopwords-iso")
my_stop_words <- tibble(
  word = c(
    "jedan",
    "e","prvi", "dva","dvije","drugi",
    "tri","tre?i","pet","kod",
    "ove","ova",  "ovo","bez",
    "evo","oko",  "om", "ek",
    "mil","tko","?est", "sedam",
    "osam",   "?im", "zbog",
    "prema", "dok","zato", "koji", 
    "im", "?ak","me?u", "tek",
    "koliko", "tko","kod","poput", 
    "ba?", "dakle", "osim", "svih", 
    "svoju", "odnosno", "gdje",
    "kojoj", "ovi", "toga","ima","treba","sad","to","kad", "?e","ovaj","?ta","onda","ce","ko"
  ),
  lexicon = "lux"
)
stop_corpus <- my_stop_words %>%
  bind_rows(stopwords_cro)

```

### Najčešći unigrami i bigrami

```{r najbitnije_rijeci, echo=FALSE, message=FALSE, warning=FALSE}

##korpus rijeci

hdz %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_corpus, by = "word") %>%
  mutate(word = gsub("\\d+", NA, word)) %>%
  mutate(word = gsub("^[a-zA-Z]$", NA, word)) %>%
  filter(!is.na(word)) -> rijeci_clean


rijeci_clean %>%
  group_by(word) %>%
  count() %>%
  arrange(desc(n)) %>% 
  ungroup() %>%
  filter(n>50|n<460)-> pregled


pregled %>%
  slice(-c(1:5))%>%
  filter(n>50) %>%
  kable() %>%
    kable_styling() %>%
    scroll_box(width = "500px", height = "400px")



## End(Not run)



##korpus bigram

hdz %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  count(bigram, sort = TRUE) -> kandidati_bigram 


bigrams_separated <- kandidati_bigram %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_corpus$word) %>%
  filter(!word2 %in% stop_corpus$word) %>%
  filter(!grepl("\\d+", word1)) %>%
  filter(!grepl("\\d+", word2)) %>% 
  filter(!grepl("^[a-zA-Z]$", word1)) %>%
  filter(!grepl("^[a-zA-Z]$", word2)) 

# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ") %>%
  slice(-c(1:13))

bigrams_united %>% 
  slice(1:200) %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(width = "500px", height = "400px")

```



## Analiza

